{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author Emmanuel Sedicol\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uninverted/ Inverted 2D Court (x,y) Coordinates\n",
    "\n",
    "Four Corners:\n",
    "- bottom left, top left, bottom right, top right\n",
    "- uninvert - [(0, 400), (0, 0), (600, 400), (600, 0)]\n",
    "- invert - [(0, 400), (0, 0), (600, 400), (600, 0)]\n",
    "\n",
    "Free Throw Section:\n",
    "- bottom left, top left, bottom right, top right\n",
    "- uninvert - [(226, 400), (226, 240), (394, 400), (394, 240)]\n",
    "- invert - [(226, 160), (226, 0), (370, 160), (370, 0)]\n",
    "\n",
    "Three Point Arc Section \n",
    "- left, center, right\n",
    "- uninvert - [(63, 400), (300, 185), (535, 400)]\n",
    "- invert - [(63, 0), (300, 216), (535, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Position Extraction using Using Hough Transform Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    pts_3D = np.array([(0,235), (70, 236), (230, 235), (370, 232), (530, 230), (600, 227), (300, 360), (200, 315), (405, 310)])\n",
    "    pts_2D = np.array([(0, 0), (63, 0),(226, 0), (370, 0), (535, 0), (600, 0), (300, 216), (226, 160), (370, 160) ])\n",
    "\n",
    "    frame = cv2.imread('images/court/court_extraction.png')\n",
    "    frame  = cv2.resize(frame, (600,400))\n",
    "\n",
    "    court = cv2.imread('images/court/court_invert.png')\n",
    "    court  = cv2.resize(court, (600,400))\n",
    "\n",
    "    roi = frame[150:400, 0: 600]\n",
    "\n",
    "    r_h, r_w, r_c = roi.shape\n",
    "    i_h, i_w, i_c = frame.shape\n",
    "\n",
    "    # line detection works better with grayscale images (less pixel range to process)\n",
    "    gray = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Canny edge detection to detect line edges\n",
    "    edges = cv2.Canny(roi, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "\n",
    "    # calculate (x1,y1) and (x2, y2) coordinates\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "\n",
    "        # extend lines out \n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "        cv2.line(frame, (x1, y1 + (i_h - r_h)), (x2, y2 + (i_h - r_h)), (255, 0 ,100), 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    fig.suptitle(\"PLAYER POSITION EXTRACTION\")\n",
    "\n",
    "    ax1.set_title(\"3D Image\")\n",
    "    for p in range(0, len(pts_3D)):\n",
    "        ax1.scatter(pts_3D[p][0], pts_3D[p][1], s=100, c='r', marker='o')\n",
    "\n",
    "    ax2.set_title(\"2D Image\")\n",
    "    for p in range(0, len(pts_2D)):\n",
    "        ax2.scatter(pts_2D[p][0], pts_2D[p][1], s=200, c='r')\n",
    "\n",
    "    ax1.imshow(frame)\n",
    "    ax2.imshow(court)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for locating and mapping the positon of a person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_position(frame, court, pts_3D, pts_2D):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    # yellow lower and upper range\n",
    "    lower_range = (10, 160, 160)                       \n",
    "    upper_range = (100,255,255)  \n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # morph points from 3D frame onto the corrensponding point located on the 2D court image\n",
    "    matrix, status = cv2.findHomography(pts_3D, pts_2D)\n",
    "    warped_frame = cv2.warpPerspective(frame, matrix, (court.shape[1], court.shape[0]))\n",
    "    \n",
    "    # image filtering for a better color detection\n",
    "    image = cv2.cvtColor(warped_frame, cv2.COLOR_BGR2RGB)\n",
    "    blur = cv2.GaussianBlur(image, (15, 15),0)\n",
    "    erode = cv2.erode(blur, None, iterations=2)\n",
    "    dilate = cv2.dilate(erode, None, iterations=2)\n",
    "    hsv = cv2.cvtColor(dilate, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # using the yellow color range we create a mask retrieving objects that contains values between the range\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)  \n",
    "\n",
    "    # retrieve contours from mask\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    if  len(cnts) > 0: \n",
    "        # using the max contour value we create a minimum enclosing circle on the contour to get an estimation of the center points\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\n",
    "        if radius > 5:\n",
    "            # mark positions\n",
    "            court = cv2.circle(court.copy(), (int(x), int(y)), 3, (0, 255, 100), 3) \n",
    "            cv2.putText(court, f'(x={round(x , 1)}, y={round(y, 1)})', (int(x - 90), int(y + 35)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (25, 255, 25), 2 )\n",
    "\n",
    "    return warped_frame, mask, court, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test position estimation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    frame2 = cv2.imread('/images/court/court_extraction.png')\n",
    "    frame2  = cv2.resize(frame, (600,400))\n",
    "    warped_frame, mask, court, _, _ =  estimate_position(frame2, court, pts_3D, pts_2D)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    ax1.set_title(\"Warped Image\")\n",
    "    ax2.set_title(\"Mask\")\n",
    "    ax3.set_title(\"Estimate Player Position\")\n",
    "\n",
    "    ax1.imshow(warped_frame)\n",
    "    ax2.imshow(mask)\n",
    "    ax3.imshow(cv2.cvtColor(court, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
